{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 8154688512.0\n",
      "Epoch: 100 Loss: 8143764992.0\n",
      "Epoch: 200 Loss: 8132868096.0\n",
      "Epoch: 300 Loss: 8121996800.0\n",
      "Epoch: 400 Loss: 8111153664.0\n",
      "Epoch: 500 Loss: 8100337152.0\n",
      "Epoch: 600 Loss: 8089545728.0\n",
      "Epoch: 700 Loss: 8078783488.0\n",
      "Epoch: 800 Loss: 8068045312.0\n",
      "Epoch: 900 Loss: 8057335808.0\n",
      "Epoch: 1000 Loss: 8046651392.0\n",
      "Epoch: 1100 Loss: 8035995136.0\n",
      "Epoch: 1200 Loss: 8025366528.0\n",
      "Epoch: 1300 Loss: 8014761984.0\n",
      "Epoch: 1400 Loss: 8004187136.0\n",
      "Epoch: 1500 Loss: 7993637888.0\n",
      "Epoch: 1600 Loss: 7983114752.0\n",
      "Epoch: 1700 Loss: 7972617728.0\n",
      "Epoch: 1800 Loss: 7962147840.0\n",
      "Epoch: 1900 Loss: 7951705088.0\n",
      "Epoch: 2000 Loss: 7941288960.0\n",
      "Epoch: 2100 Loss: 7930897920.0\n",
      "Epoch: 2200 Loss: 7920534528.0\n",
      "Epoch: 2300 Loss: 7910200320.0\n",
      "Epoch: 2400 Loss: 7899890688.0\n",
      "Epoch: 2500 Loss: 7889608192.0\n",
      "Epoch: 2600 Loss: 7879352832.0\n",
      "Epoch: 2700 Loss: 7869124608.0\n",
      "Epoch: 2800 Loss: 7858922496.0\n",
      "Epoch: 2900 Loss: 7848748544.0\n",
      "Epoch: 3000 Loss: 7838601216.0\n",
      "Epoch: 3100 Loss: 7828479488.0\n",
      "Epoch: 3200 Loss: 7818385408.0\n",
      "Epoch: 3300 Loss: 7808318976.0\n",
      "Epoch: 3400 Loss: 7798277632.0\n",
      "Epoch: 3500 Loss: 7788264448.0\n",
      "Epoch: 3600 Loss: 7778277376.0\n",
      "Epoch: 3700 Loss: 7768316416.0\n",
      "Epoch: 3800 Loss: 7758383104.0\n",
      "Epoch: 3900 Loss: 7748476416.0\n",
      "Epoch: 4000 Loss: 7738595840.0\n",
      "Epoch: 4100 Loss: 7728742400.0\n",
      "Epoch: 4200 Loss: 7718916096.0\n",
      "Epoch: 4300 Loss: 7709115392.0\n",
      "Epoch: 4400 Loss: 7699342848.0\n",
      "Epoch: 4500 Loss: 7689595392.0\n",
      "Epoch: 4600 Loss: 7679876608.0\n",
      "Epoch: 4700 Loss: 7670183424.0\n",
      "Epoch: 4800 Loss: 7660517376.0\n",
      "Epoch: 4900 Loss: 7650877440.0\n",
      "Epoch: 5000 Loss: 7641264128.0\n",
      "Epoch: 5100 Loss: 7631679488.0\n",
      "Epoch: 5200 Loss: 7622119424.0\n",
      "Epoch: 5300 Loss: 7612586496.0\n",
      "Epoch: 5400 Loss: 7603081216.0\n",
      "Epoch: 5500 Loss: 7593601536.0\n",
      "Epoch: 5600 Loss: 7584150016.0\n",
      "Epoch: 5700 Loss: 7574724608.0\n",
      "Epoch: 5800 Loss: 7565324800.0\n",
      "Epoch: 5900 Loss: 7555953152.0\n",
      "Epoch: 6000 Loss: 7546608640.0\n",
      "Epoch: 6100 Loss: 7537289216.0\n",
      "Epoch: 6200 Loss: 7527997440.0\n",
      "Epoch: 6300 Loss: 7518732288.0\n",
      "Epoch: 6400 Loss: 7509494272.0\n",
      "Epoch: 6500 Loss: 7500282880.0\n",
      "Epoch: 6600 Loss: 7491097600.0\n",
      "Epoch: 6700 Loss: 7481939456.0\n",
      "Epoch: 6800 Loss: 7472807424.0\n",
      "Epoch: 6900 Loss: 7463703040.0\n",
      "Epoch: 7000 Loss: 7454626304.0\n",
      "Epoch: 7100 Loss: 7445574144.0\n",
      "Epoch: 7200 Loss: 7436550144.0\n",
      "Epoch: 7300 Loss: 7427552768.0\n",
      "Epoch: 7400 Loss: 7418582016.0\n",
      "Epoch: 7500 Loss: 7409636864.0\n",
      "Epoch: 7600 Loss: 7400720384.0\n",
      "Epoch: 7700 Loss: 7391828992.0\n",
      "Epoch: 7800 Loss: 7382965760.0\n",
      "Epoch: 7900 Loss: 7374128640.0\n",
      "Epoch: 8000 Loss: 7365318144.0\n",
      "Epoch: 8100 Loss: 7356534784.0\n",
      "Epoch: 8200 Loss: 7347777024.0\n",
      "Epoch: 8300 Loss: 7339047424.0\n",
      "Epoch: 8400 Loss: 7330343424.0\n",
      "Epoch: 8500 Loss: 7321667584.0\n",
      "Epoch: 8600 Loss: 7313015808.0\n",
      "Epoch: 8700 Loss: 7304388608.0\n",
      "Epoch: 8800 Loss: 7295787520.0\n",
      "Epoch: 8900 Loss: 7287215104.0\n",
      "Epoch: 9000 Loss: 7278667776.0\n",
      "Epoch: 9100 Loss: 7270147584.0\n",
      "Epoch: 9200 Loss: 7261654016.0\n",
      "Epoch: 9300 Loss: 7253186560.0\n",
      "Epoch: 9400 Loss: 7244746752.0\n",
      "Epoch: 9500 Loss: 7236334080.0\n",
      "Epoch: 9600 Loss: 7227948032.0\n",
      "Epoch: 9700 Loss: 7219588096.0\n",
      "Epoch: 9800 Loss: 7211255296.0\n",
      "Epoch: 9900 Loss: 7202949120.0\n",
      "Test Loss: 4091153920.0\n",
      "weight - Parameter containing:\n",
      "tensor([[9.4249]], requires_grad=True), bias - Parameter containing:\n",
      "tensor([0.6916], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.model = nn.Linear(1, 1)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=0.001)    \n",
    "\n",
    "    def getData(self) -> np.array:\n",
    "        data = pd.read_csv('House_Rent_Dataset.csv')\n",
    "        data = data[[\"Rent\",\"Size\"]]\n",
    "        x_train, x_test, y_train, y_test = train_test_split(data[\"Size\"], data[\"Rent\"], test_size=0.25, random_state=42)\n",
    "        return x_train, x_test, y_train, y_test\n",
    "        \n",
    "\n",
    "    def executeModel(self, epochs = 10000):\n",
    "        x_train, x_test, y_train, y_test = self.getData()\n",
    "\n",
    "        x_train = torch.tensor(x_train.values).float().view(-1, 1)\n",
    "        y_train = torch.tensor(y_train.values).float().view(-1, 1)\n",
    "        x_test = torch.tensor(x_test.values).float().view(-1, 1)\n",
    "        y_test = torch.tensor(y_test.values).float().view(-1, 1)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            y_train_pred = self.model(x_train)\n",
    "            loss = self.criterion(y_train_pred, y_train)\n",
    "            loss.backward()\n",
    "            # Add gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)            \n",
    "            self.optimizer.step()\n",
    "            if epoch % 100 == 0:\n",
    "                print('Epoch:', epoch, 'Loss:', loss.item())\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_test_pred = self.model(x_test)\n",
    "            test_loss = self.criterion(y_test_pred, y_test)\n",
    "            print('Test Loss:', test_loss.item())\n",
    "\n",
    "        print(f\"weight - {self.model.weight}, bias - {self.model.bias}\")\n",
    "\n",
    "        return self.model\n",
    "\n",
    "regression = LinearRegression()\n",
    "regression.executeModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
